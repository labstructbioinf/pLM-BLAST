{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import numba\n",
    "import datetime\n",
    "import time\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb_path = '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/0.emb'\n",
    "\n",
    "emb_list_path = ['/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/0.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/2.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/3.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/5.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/6.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/7.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/8.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/11.emb', \n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/12.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/17.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/22.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/26.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/28.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/30.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/32.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/39.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/43.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/46.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/50.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/51.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/55.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/57.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/59.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/62.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/66.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/68.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/71.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/76.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/79.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/81.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/93.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/94.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/95.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/108.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/121.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/124.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/125.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/126.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/137.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/141.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/142.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/145.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/146.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/159.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/160.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/161.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/162.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/169.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/170.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/171.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/172.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/173.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/176.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/178.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/181.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/184.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/186.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/190.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/194.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/198.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/199.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/201.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/203.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/204.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/213.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/214.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/219.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/222.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/227.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/228.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/229.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/230.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/234.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/235.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/238.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/244.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/245.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/247.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/249.emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb_path = '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/0.emb'\n",
    "\n",
    "emb_list_path1 = ['/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/0.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/2.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/3.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/5.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/6.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/7.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/8.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/11.emb', \n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/12.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/17.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/22.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/26.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/28.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/30.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/32.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/39.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/43.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/46.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/50.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/51.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/55.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/57.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/59.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/62.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/66.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/68.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/71.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/76.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/79.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/81.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/93.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/94.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/95.emb']\n",
    "emb_list_path2 = ['/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/108.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/121.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/124.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/125.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/126.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/137.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/141.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/142.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/145.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/146.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/159.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/160.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/161.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/162.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/169.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/170.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/171.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/172.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/173.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/176.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/178.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/181.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/184.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/186.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/190.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/194.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/198.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/199.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/201.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/203.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/204.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/213.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/214.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/219.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/222.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/227.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/228.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/229.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/230.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/234.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/235.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/238.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/244.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/245.emb', '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/247.emb',\n",
    "            '/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/249.emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit('f4[:,:](f4[:,:], f4[:,:])', nogil=True, fastmath=True, cache=True)\n",
    "def embedding_local_similarity(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "\t'''\n",
    "\tcompute X, Y similarity by matrix multiplication\n",
    "\tresult shape [num X residues, num Y residues]\n",
    "\tArgs:\n",
    "\t\tX, Y: - (np.ndarray 2D) protein embeddings as 2D tensors\n",
    "\t\t  [num residues, embedding size]\n",
    "\tReturns:\n",
    "\t\tdensity (np.ndarray)\n",
    "\t'''\n",
    "\tassert X.ndim == 2 and Y.ndim == 2\n",
    "\tassert X.shape[1] == Y.shape[1]\n",
    "\n",
    "\txlen: int = X.shape[0]\n",
    "\tylen: int = Y.shape[0]\n",
    "\tembdim: int = X.shape[1]\n",
    "\t# normalize\n",
    "\temb1_norm: np.ndarray = np.empty((xlen, 1), dtype=np.float32)\n",
    "\temb2_norm: np.ndarray = np.empty((ylen, 1), dtype=np.float32)\n",
    "\temb1_normed: np.ndarray = np.empty((xlen, embdim), dtype=np.float32)\n",
    "\temb2_normed: np.ndarray = np.empty((ylen, embdim), dtype=np.float32)\n",
    "\tdensity: np.ndarray = np.empty((xlen, ylen), dtype=np.float32)\n",
    "\t# numba does not support sum() args other then first\n",
    "\temb1_norm = np.expand_dims(np.sqrt(np.power(X, 2).sum(1)), 1)\n",
    "\temb2_norm = np.expand_dims(np.sqrt(np.power(Y, 2).sum(1)), 1)\n",
    "\temb1_normed = X / emb1_norm\n",
    "\temb2_normed = Y / emb2_norm\n",
    "\tdensity = (emb1_normed @ emb2_normed.T).T\n",
    "\treturn density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "embeddings = [torch.load(f).float().numpy() for f in emb_list_path]\n",
    "query_emb = torch.load(query_emb_path)\n",
    "query_emb = query_emb.float().numpy()\n",
    "\n",
    "for emb in embeddings:\n",
    "    if not np.issubdtype(query_emb.dtype, np.float32):\n",
    "        query_emb = query_emb.astype(np.float32)\n",
    "    if not np.issubdtype(emb.dtype, np.float32):\n",
    "        emb = emb.astype(np.float32)\n",
    "        \n",
    "    densitymap = embedding_local_similarity(query_emb, emb)\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_local_similarity_gpu(X, Y):\n",
    "    assert X.ndim == 2 and Y.ndim == 2, 'input tensors must have 2 dims [num residues, embedding dim]'\n",
    "    assert X.shape[1] == Y.shape[1], f'embedding size is different for X, Y - {X.shape[1]} and {Y.shape[1]}'\n",
    "\n",
    "    # normalize\n",
    "    emb1_normed = X / X.pow(2).sum(1, keepdim=True).sqrt()\n",
    "    emb2_normed = Y / Y.pow(2).sum(1, keepdim=True).sqrt()\n",
    "\n",
    "    # emb1_normed = X / torch.linalg.norm(X, dim=1, keepdim=True)\n",
    "    # emb2_normed = Y / torch.linalg.norm(Y, dim=1, keepdim=True)\n",
    "\n",
    "    if emb1_normed.shape[1] != emb2_normed.shape[1]:\n",
    "        raise ValueError(f\"Shape mismatch: emb1_normed.shape[1] ({emb1_normed.shape[1]}) != emb2_normed.shape[1] ({emb2_normed.shape[1]})\")\n",
    "\n",
    "    density = torch.matmul(emb1_normed, emb2_normed.T).T\n",
    "\n",
    "    density = density.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    return density\n",
    "\n",
    "def compute_densitymaps(query_emb, embedding_list):\n",
    "    device = torch.device('cuda')\n",
    "    qe = torch.load(query_emb, map_location=device)\n",
    "    densitymaps = []\n",
    "    for emb in embedding_list:\n",
    "        te = torch.load(emb, map_location=device)\n",
    "        if qe.shape[1] != te.shape[1]:\n",
    "            raise ValueError(f\"Shape mismatch: qe.shape[1] ({qe.shape[1]}) != te.shape[1] ({te.shape[1]})\")\n",
    "        densitymap = embedding_local_similarity_gpu(qe, te)\n",
    "        densitymaps.append(densitymap)\n",
    "    return densitymaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "densitymaps = compute_densitymaps(query_emb_path, emb_list_path)\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_local_similarity_gpu2(X, Y):\n",
    "    assert X.ndim == 2 and Y.ndim == 2, 'input tensors must have 2 dims [num residues, embedding dim]'\n",
    "    assert X.shape[1] == Y.shape[1], f'embedding size is different for X, Y - {X.shape[1]} and {Y.shape[1]}'\n",
    "\n",
    "    # normalize\n",
    "    # emb1_normed = X / X.pow(2).sum(1, keepdim=True).sqrt()\n",
    "    # emb2_normed = Y / Y.pow(2).sum(1, keepdim=True).sqrt()\n",
    "\n",
    "    emb1_normed = X / torch.linalg.norm(X, dim=1, keepdim=True)\n",
    "    emb2_normed = Y / torch.linalg.norm(Y, dim=1, keepdim=True)\n",
    "\n",
    "    if emb1_normed.shape[1] != emb2_normed.shape[1]:\n",
    "        raise ValueError(f\"Shape mismatch: emb1_normed.shape[1] ({emb1_normed.shape[1]}) != emb2_normed.shape[1] ({emb2_normed.shape[1]})\")\n",
    "\n",
    "    density = torch.matmul(emb1_normed, emb2_normed.T).T\n",
    "\n",
    "    density = density.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    return density\n",
    "\n",
    "def compute_densitymaps2(query_emb, embedding_list):\n",
    "    device = torch.device('cuda')\n",
    "    qe = torch.load(query_emb, map_location=device)\n",
    "    densitymaps = []\n",
    "    for emb in embedding_list:\n",
    "        te = torch.load(emb, map_location=device)\n",
    "        if qe.shape[1] != te.shape[1]:\n",
    "            raise ValueError(f\"Shape mismatch: qe.shape[1] ({qe.shape[1]}) != te.shape[1] ({te.shape[1]})\")\n",
    "        densitymap = embedding_local_similarity_gpu2(qe, te)\n",
    "        densitymaps.append(densitymap)\n",
    "    return densitymaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "densitymaps = compute_densitymaps2(query_emb_path, emb_list_path)\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba time: 0:00:00.014239\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "embeddings = [torch.load(f).float().numpy() for f in emb_list_path2]\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "embeddings = [torch.load(f) for f in emb_list_path]\n",
    "embeddingss = [f.to(device) for f in embeddings]\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingss[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba time: 0:00:00.016170\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "embeddings1 = [torch.load(f, map_location=device) for f in emb_list_path1]\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "embeddings2 = [torch.load(f, map_location=device) for f in emb_list_path2]\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "buffer = []\n",
    "for emb in emb_list_path:\n",
    "    with open(emb, 'rb') as f:\n",
    "        buffer.append(f.read())\n",
    "\n",
    "embeddingi_tensor_gpu =[]\n",
    "for b in buffer:\n",
    "    buffer_io = io.BytesIO(b)\n",
    "    embeddingi_tensor_gpu = torch.load(buffer_io, map_location='cuda')\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ścieżka do pliku .pt z embeddingami\n",
    "path_to_embeddings = query_emb_path\n",
    "\n",
    "\n",
    "# Wczytaj dane do pamięci RAM\n",
    "start_ram = time.time()\n",
    "with open(path_to_embeddings, 'rb') as f:\n",
    "    buffer = f.read()\n",
    "end_ram = time.time()\n",
    "print(f\"Czas wczytywania do RAM: {end_ram - start_ram:.4f} sekund\")\n",
    "\n",
    "# Przenieś dane z RAM na GPU\n",
    "start_gpu = time.time()\n",
    "buffer_io = io.BytesIO(buffer)\n",
    "embeddingi_tensor_gpu = torch.load(buffer_io, map_location='cuda')\n",
    "end_gpu = time.time()\n",
    "print(f\"Czas przenoszenia z RAM na GPU: {end_gpu - start_gpu:.4f} sekund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(path):\n",
    "    return torch.load(path, map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(load_embedding, f) for f in emb_list_path]\n",
    "    embeddings = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_embeddings = torch.cat([torch.load(f) for f in emb_list_path])\n",
    "torch.save(consolidated_embeddings, 'consolidated_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "embeddings = torch.load('consolidated_embeddings.pt', map_location='cuda')\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_gpu = torch.load('/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/0.emb', map_location='cuda')\n",
    "te_gpu = torch.load('/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/2.emb', map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_cpu = torch.load('/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/0.emb').float().numpy()\n",
    "te_cpu = torch.load('/home/nfs/kpawlicki/magisterka/db/vikram/vikram_ecod_no_dup2/2.emb').float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "embedding_local_similarity(qe_cpu, te_cpu)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "embedding_local_similarity_gpu2(qe_gpu, te_gpu)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "embedding_local_similarity_gpu(qe_gpu, te_gpu)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'Numba time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
